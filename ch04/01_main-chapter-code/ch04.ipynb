{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2689201",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96c08a",
   "metadata": {},
   "source": [
    "- We use short variable names to avoid long lines of code later.\n",
    "- \"vocab_size\" indicates a vocabulary size of 50,257 words, supoorted by the BPE tokenizer discussed in Chapter 2.\n",
    "- \"context_length\" represents the model's maximum input token count, as enabled by positional embeddings covered in chapter 2. (需要回忆整理, n_gram和预测下一个词)\n",
    "- \"emb_dim\" is the embedding size for token inputs, converting each input token into a 768-dimensinal vector.\n",
    "- \"n_heads\" is the number of attention heads in the multi-head attention mechanism implemented in chapter 3.\n",
    "- \"n_layers\" is the number of transformers blocks within the model, which we'll implement in upcoming sections.\n",
    "- \"drop_rate\" is the dropout mechanism's intensity, discussed in chapter 3. 0.1 means dropping 10% of hidden units during training to mitigate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977538a6",
   "metadata": {},
   "source": [
    "# GPT模型构建流程图（基于图示结构）\n",
    "\n",
    "1. GPT backbone  \n",
    "   ↳ We start this chapter by implementing a GPT placeholder model to see the overall structure of the model\n",
    "\n",
    "   ├──▶ 2. Layer normalization  \n",
    "   ├──▶ 3. GELU activation  \n",
    "   ├──▶ 4. Feed forward network  \n",
    "   └──▶ 5. Shortcut connections  \n",
    "         ↳ In the upcoming sections, we implement the different building blocks 2–5 that are used inside a GPT model!\n",
    "\n",
    "              ↓  \n",
    "           Combined into  \n",
    "              ↓\n",
    "\n",
    "6. Transformer block  \n",
    "   ↳ We combine the building blocks 2–5, including the multi-head attention module covered in the previous chapter, into a transformer block\n",
    "\n",
    "        ↓  \n",
    "\n",
    "7. Final GPT architecture  \n",
    "   ↳ At the end of this chapter, we use multiple transformer blocks to implement the GPT model that we will train in the upcoming chapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff89c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/a1/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/r6/9cx1mcz91n11jbr0ptrq84rm0000gn/T/ipykernel_88467/1390525803.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2247356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab097a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2773bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.3215, 1.0881, 0.0000, 0.5991, 0.0000],\n",
      "        [0.0000, 0.1669, 0.0000, 0.4879, 0.3727, 0.8047]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f5cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.3348],\n",
      "        [0.3053]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.1948],\n",
      "        [0.0986]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b697b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[-0.7586, -0.0301,  1.7071, -0.7586,  0.5989, -0.7586],\n",
      "        [-0.9726, -0.4411, -0.9726,  0.5814,  0.2145,  1.5904]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[3.9736e-08],\n",
      "        [9.9341e-09]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74980436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"mean:\\n\", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "669f2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057679c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln=ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99db46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "Var:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Var:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf57fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f9f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (y, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m([y_gelu, y_relu], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGELU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREUL\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, i)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m activation function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/pyplot.py:3838\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3832\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3836\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3837\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/axes/_base.py:483\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    480\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 483\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/cbook.py:1361\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001b[39;00m\n\u001b[0;32m-> 1361\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43m_unpack_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/matplotlib/cbook.py:2371\u001b[0m, in \u001b[0;36m_unpack_to_numpy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m xtmp\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_jax_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_tensorflow_array(x):\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;66;03m# using np.asarray() instead of explicitly __array__(), as the latter is\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;66;03m# only _one_ of many methods, and it's the last resort, see also\u001b[39;00m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;66;03m# https://numpy.org/devdocs/user/basics.interoperability.html#using-arbitrary-objects-in-numpy\u001b[39;00m\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;66;03m# therefore, let arrays do better if they can\u001b[39;00m\n\u001b[0;32m-> 2371\u001b[0m     xtmp \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;66;03m# In case np.asarray method does not return a numpy array in future\u001b[39;00m\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xtmp, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"f{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad1f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c3bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015f88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "    \n",
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62308f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8015c6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a21154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c4c74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  torch.Size([2, 4, 768])\n",
      "output:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)   # [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"input: \", x.shape)\n",
    "print(\"output: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ad0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37382420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"input batch:\\n\", batch)\n",
    "print(\"\\noutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14767aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a19b36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa77901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06be0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1508a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457e19c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "output length:  10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"output: \", out)\n",
    "print(\"output length: \", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f9b6c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
